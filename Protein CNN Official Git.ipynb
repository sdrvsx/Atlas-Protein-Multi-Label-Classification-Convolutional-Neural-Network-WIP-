{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset and Unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_USERNAME'] = \"sanjayratnayake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_KEY'] = \"6f91a84af950a57266320cc14164d052\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!kaggle competitions download -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('/home/sanjaya_ratnayake_d/human-protein-atlas-image-classification.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/home/sanjaya_ratnayake_d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CSV and Prepare Dataframe of files/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"/home/sanjaya_ratnayake_d/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping_csv = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mapping_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping_csv['Id'] = mapping_csv['Id'] + '_green'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = \"/home/sanjaya_ratnayake_d/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idtarget = {}\n",
    "for filename in listdir(folder):\n",
    "    if filename.endswith('_green.png'):\n",
    "        pass\n",
    "    else:\n",
    "        idtarget[filename[:-4]] = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame.from_dict(idtarget, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3 = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.columns = ['Id', 'Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3['Target'] = df3['Target'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dffinal = pd.concat([mapping_csv, df3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dffinal = dffinal.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dffinal = dffinal.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dffinal['Target'] = dffinal['Target'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dffinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folder2x = \"/home/sanjaya_ratnayake_d/trainset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dflist = []\n",
    "for file in os.listdir(folder2x):\n",
    "    dflist.append(file[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered = dffinal['Id'].isin(dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dffinal2 = dffinal[filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dffinal3 = dffinal2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dffinal3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dffinal3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#File mappings of filename to label\n",
    "def create_file_mapping(dffinal3):\n",
    "    mapping = {}\n",
    "    for i in range(len(dffinal3)):\n",
    "        name, tags = dffinal3['Id'][i], dffinal3['Target'][i]\n",
    "        mapping[name] = tags.split()\n",
    "    return mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One Hot Encode tags for individual files\n",
    "def one_hot_encode(tags, mapping):\n",
    "        encoding = np.zeros(29)\n",
    "        for tag in tags:\n",
    "            tag = int(tag)\n",
    "            encoding[tag] = 1\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load all images into memory\n",
    "def load_dataset(path, file_mapping):\n",
    "    photos, targets = list(), list()\n",
    "    n = 0\n",
    "    for filename in listdir(folder2x):\n",
    "        n = n+1\n",
    "        print(\"picture number {}\".format(n))\n",
    "        #load image\n",
    "        photo = load_img(path + filename, target_size=(512,512))\n",
    "        #convert to numpy array\n",
    "        photo = img_to_array(photo)\n",
    "        tags = file_mapping[filename[:-4]]\n",
    "        #one hot encode\n",
    "        target = one_hot_encode(tags, file_mapping)\n",
    "        #store\n",
    "        photos.append(photo)\n",
    "        targets.append(target)\n",
    "    X = np.asarray(photos, dtype = 'uint8')\n",
    "    y = np.asarray(targets, dtype = 'uint8')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_mapping = create_file_mapping(dffinal3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder3x = \"/home/sanjaya_ratnayake_d/trainset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = load_dataset(folder3x, file_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savez_compressed('protein_data.npz', X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load train and test data\n",
    "def load_dataset2():\n",
    "    data = load('protein_data.npz')\n",
    "    X, y = data['arr_0'], data['arr_1']\n",
    "    trainX, testX, trainY, testY = sk.train_test_split(X, y , test_size=0.3, random_state=1)\n",
    "    print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate fbeta score\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "    y_pred = backend.clip(y_pred, 0, 1)\n",
    "    #calculate true positives, false positives, false negatives\n",
    "    tp = backend.sum(backend.round(backend.clip(y_true*y_pred, 0, 1)), axis=1)\n",
    "    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis = 1)\n",
    "    #calculate precision\n",
    "    p = tp / (tp + fp + backend.epsilon())\n",
    "    #calculate recall\n",
    "    r = tp / (tp + fn +backend.epsilon())\n",
    "    #calculate fbeta, averaged across each class\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon())\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define model\n",
    "def define_model(in_shape(512,512,3), out_shape=29):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(512, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
    "    model.add(Conv2D(512, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(29, activation='relu', kernel_initializer='he_uniform'))\n",
    "    mode.add(Dense(out_shape, activation='sigmoid'))\n",
    "    #compile model\n",
    "    opt=SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_it = datagen.flow(trainX, trainY, batch_size=128)\n",
    "test_it = datagen.flow(testX, testY, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "    validation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "print('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Fbeta')\n",
    "    pyplot.plot(history.history['fbeta'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_fbeta'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset2()\n",
    "    # create data generator\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    # prepare iterators\n",
    "    train_it = datagen.flow(trainX, trainY, batch_size=128)\n",
    "    test_it = datagen.flow(testX, testY, batch_size=128)\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "        validation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=0)\n",
    "    # evaluate model\n",
    "    loss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "    print('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder4x = \"/home/sanjaya_ratnayake_d/trainset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset3(folder4x): \n",
    "    photos = list() \n",
    "    for filename in listdir(folder4x): \n",
    "        #load image \n",
    "        photo = load_img(path + filename, target_size=(512,512)) \n",
    "        #convert to numpy array \n",
    "        photo = img_to_array(photo) \n",
    "        tags = file_mapping[filename[:-4]]  \n",
    "        #store \n",
    "        photos.append(photo) \n",
    "    X = np.asarray(photos, dtype = 'uint8')  \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = load_dataset3(folder4x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testresults = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_yhat = np.asarray([np.ones(trainY.shape[1]) for _ in range(trainY.shape[0])])\n",
    "test_yhat = np.asarray([ones(testY.shape[1]) for _ in range(testY.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_score = fbeta_score(trainY, train_yhat, 2, average='samples')\n",
    "test_score = fbeta_score(testY, test_yhat, 2, average='samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('All Ones: train=%.3f, test=%.3f' % (train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = n+1\n",
    "        print(\"picture number {}\".format(n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
